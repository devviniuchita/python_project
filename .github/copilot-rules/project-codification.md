---
metadata: |
name: '.github/copilot-rules/project-codification.md'
description: 'Coding standards, security rules, UI/UX guidelines, API conventions, logging practices, testing strategies, deployment configurations, and documentation requirements for the PYTHON_PROJECT.'
aiOptimized: true
alwaysApply: false
applyManually: true
syncWith: ['.github\copilot-rules\project-rules.md'](project-rules.md)
---

**ğŸ¯ OBJETIVO**: Garantir padrÃµes de design, arquitetura, engenharia e DNA de codificaÃ§Ã£o do PYTHON_PROJECT estabelecidos e padronizados. Para manter um cÃ³digo limpo, modular, seguro, performÃ¡tico e fÃ¡cil de manter, evoluir com escalabilidade.

---

# ğŸ—ºï¸ QUICK NAVIGATION INDEX

> **For AI Agents:** Use `read_file(offset, limit)` with line ranges below for token-efficient context retrieval (70% reduction vs full file read). For architectural concepts, see [project-rules.md](project-rules.md#quick-navigation-index).

## ğŸ—ï¸ CLEAN ARCHITECTURE - 4 LAYERS (Lines 85-1087)

- [Layer 1: Presentation (CLI/HTTP)](#1-camada-apresentaÃ§Ã£o-presentation-layer) â†’ Lines 91-303 | **Files:** `scripts/chat.py`, `src/features/conversation/conversation.py` | **Keywords:** Command Pattern, @traceable, graph.invoke()
- [Layer 2: Orchestration (LangGraph)](#2-camada-orquestraÃ§Ã£o-orchestrationgraph-layer) â†’ Lines 304-655 | **Files:** `src/features/conversation/graph.py`, `src/features/rag/graph.py` | **Keywords:** StateGraph, add_node, add_edge, compile()
- [Layer 3: Business Logic (RAG Nodes)](#3-camada-lÃ³gica-business-logic--rag-nodes) â†’ Lines 656-887 | **Files:** `src/features/rag/nodes.py`, `src/features/reranking/reranker.py` | **Keywords:** retrieve_adaptive, rerank_documents, generate_answer
- [Layer 4: Specialized Services](#4-camada-especializada) â†’ Lines 888-1087 | **Files:** `src/infrastructure/`, `src/core/services/` | **Keywords:** Settings, FAISS, LangSmith, CrossEncoder

## ğŸ“Š IMPLEMENTATION PATTERNS (Lines 1088-1470)

- [InventÃ¡rio Estruturado](#-inventÃ¡rio-estruturado-atende-t-20) â†’ Lines 1088-1123 | **Context:** File organization, module mapping
- [Linguagem Universal](#-linguagem-universal) â†’ Lines 1124-1219 | **Keywords:** Communication patterns, thread-safety, validation
- [Strategy Pattern](#1-strategy-pattern-obrigatÃ³rio-para-algoritmos) â†’ Lines 1222-1293 | **Files:** `src/features/rag/nodes.py` | **Keywords:** Callable, adaptive_retrieval, complexity routing
- [Dependency Injection](#2-dependency-injection-obrigatÃ³rio-para-gerentes) â†’ Lines 1294-1380 | **Files:** `src/core/domain/session.py` | **Keywords:** SessionConfig, Settings, lazy_load
- [Exception Hierarchy](#3-exception-hierarchy-obrigatÃ³rio-para-erros) â†’ Lines 1381-1470 | **Keywords:** Custom exceptions, error handling, retry logic

## ğŸ–ï¸ ARCHITECTURAL RULES (Lines 1471-1530)

- [Immutable Rules](#regra-1-hierarquia-sem-bypass) â†’ Lines 1471-1504 | **Keywords:** Hierarchy enforcement, no bypass, single responsibility, dependency direction
- [Architectural Validation](#-validaÃ§Ã£o-arquitetural-obrigatÃ³ria) â†’ Lines 1505-1514 | **Keywords:** Compliance tests, import-linter, architecture violations
- [Compliance Metrics](#-mÃ©tricas-de-compliance-obrigatÃ³rias) â†’ Lines 1515-1530 | **Keywords:** Test coverage, cyclomatic complexity, code duplication

## ğŸ”§ COMPLIANCE ENFORCEMENT (Lines 1531-1554)

- See [project-rules.md - COMPLIANCE](project-rules.md#-compliance-lines-595-773) for detailed enforcement rules (pre-commit, git hooks, GitHub Actions)

## ğŸ” SEARCH SHORTCUTS

### By Layer (Clean Architecture)

- **Layer 1 (Presentation):** Lines 91-303 â†’ `scripts/chat.py`, `src/features/conversation/conversation.py`
- **Layer 2 (Orchestration):** Lines 304-655 â†’ `src/features/conversation/graph.py`, `src/features/rag/graph.py`
- **Layer 3 (Business Logic):** Lines 656-887 â†’ `src/features/rag/nodes.py`, `src/features/reranking/reranker.py`
- **Layer 4 (Services):** Lines 888-1087 â†’ `src/infrastructure/`, `src/core/services/`

### By Pattern (Enterprise)

- **Strategy Pattern:** Lines 1222-1293 (adaptive retrieval, complexity routing)
- **Dependency Injection:** Lines 1294-1380 (SessionConfig, Settings composition)
- **Exception Hierarchy:** Lines 1381-1470 (custom exceptions, error handling)
- **Communication Pattern:** Lines 1124-1219 (thread-safety, validation)

### By File Reference

- **CLI Handler:** `scripts/chat.py` â†’ Lines 91-303 (Layer 1 example)
- **Conversation Graph:** `src/features/conversation/graph.py` â†’ Lines 304-655 (Layer 2 example)
- **RAG Nodes:** `src/features/rag/nodes.py` â†’ Lines 656-887, 1222-1293 (Layer 3 + Strategy)
- **Reranker:** `src/features/reranking/reranker.py` â†’ Lines 656-887 (CrossEncoder integration)
- **Session Config:** `src/core/domain/session.py` â†’ Lines 1294-1380 (DI pattern)
- **Settings:** `src/infrastructure/config/settings.py` â†’ Lines 888-1087 (Layer 4)
- **State Definition:** `src/core/domain/state.py` â†’ Lines 91-303 (RAGState, ConversationalRAGState)

### By Class/Function (Grep-Optimized)

- **RAGState:** Lines 91-303 (definition), 304-655 (graph usage), 656-887 (node transformations)
- **SessionConfig:** Lines 1294-1380 (DI pattern), 888-1087 (Layer 4 integration)
- **graph.invoke():** Lines 91-303 (Layer 1 call), 304-655 (graph compilation)
- **retrieve_adaptive:** Lines 656-887, 1222-1293 (implementation + Strategy pattern)
- **rerank_documents:** Lines 656-887 (CrossEncoder reranking)
- **generate_answer:** Lines 656-887 (LLM generation node)
- **@traceable:** Lines 91-303 (LangSmith observability)
- **StateGraph:** Lines 304-655 (LangGraph orchestration)
- **BaseSettings:** Lines 1294-1380 (Pydantic DI), 888-1087 (Layer 4 Settings)

### Cross-Reference to project-rules.md

- **SOLID Principles:** [project-rules.md Lines 96-119](project-rules.md#-solid-principles---overview)
- **OOP Patterns (Abstract):** [project-rules.md Lines 120-594](project-rules.md#-oop-implementation-patterns---deep-dive)
- **Compliance Details:** [project-rules.md Lines 595-773](project-rules.md#-compliance-lines-595-773)

---

## ğŸ—ï¸ ARQUITETURA ENTERPRISE HIERÃRQUICA - PADRÃ•ES VALIDADOS

### âœ… **CAMADA 1: APRESENTAÃ‡ÃƒO (CLI/HTTP Interface)**

A arquitetura do PYTHON_PROJECT segue **Clean Architecture** com 4 camadas hierÃ¡rquicas independentes:

#### **1. CAMADA APRESENTAÃ‡ÃƒO (Presentation Layer)**

```yaml
Responsabilidade: |
  - Parse input do usuÃ¡rio (CLI ou HTTP)
  - Dispatch comandos (/reset, /quit, /help)
  - Formatar requests para Layer 2
  - Formatar responses do Layer 2
  - Gerenciar sessÃµes de usuÃ¡rio

Conversa_com: |
  - UP: UsuÃ¡rio/Cliente (CLI stdin/stdout ou HTTP requests)
  - DOWN: Layer 2 (Orchestration) via graph.invoke()
  - SIDE: Layer 4 (Memory Manager) via get_conversation_config()

Pattern_Applied: |
  - Command Pattern: CLI command dispatch (/reset, /quit, /help)
  - Handler Pattern: Conversational node handlers (@traceable nodes)
  - Orchestration Pattern: Wraps Layer 2 graph invocation
  - Dependency Injection: Session config passed from Layer 4

Regra_RÃ­gida: |
  - NÃƒO contÃ©m lÃ³gica de negÃ³cio (delegue para Layer 2+)
  - NÃƒO contÃ©m estado persistente (delegue para Layer 4)
  - DEVE validar entrada antes de passar para Layer 2
  - DEVE formatar saÃ­da de maneira legÃ­vel ao usuÃ¡rio
  - DEVE rastrear observabilidade com @traceable
```

**Arquivos Implementadores:**

- `scripts/chat.py` - CLI handler principal (linhas 1-150)
- `src/features/conversation/conversation.py` - Handler nodes (linhas 1-240)
- `src/features/conversation/conversation_graph.py` - Orchestration wrapper (linhas 146-210)
- `src/core/services/memory_manager.py` - Session management (linhas 1-100)

```python
# âœ… PADRÃƒO CORRETO - Presentation Layer Flow

# 1. INPUT PARSING (scripts/chat.py, Line 60-75)
def run_interactive_conversation(user_id: str = "cli_user"):
    config = get_conversation_config(user_id)  # Layer 4: get session
    while True:
        user_input = input("You: ").strip()  # Parse user input

        # 2. COMMAND DISPATCH (Command Pattern)
        if user_input.startswith("/"):
            command = user_input.lower()
            if command == "/reset":
                reset_conversation(user_id)  # Layer 4: reset session
                config = get_conversation_config(user_id)
            elif command == "/quit":
                break
            continue

        # 3. REQUEST FORMATTING + LAYER 2 INVOCATION
        # File: src/features/conversation/conversation_graph.py (Line 146-165)
        def run_conversational_query(question: str, user_id: str, config: dict) -> str:
            graph = create_conversational_rag_graph()  # Layer 2: create graph
            initial_state = {
                "messages": [HumanMessage(content=question)],  # Format as message
                "question": question,
                "complexity": "",
                "documents": [],
                "generation": "",
            }
            final_state = graph.invoke(initial_state, config)  # Layer 2: invoke

            # 4. RESPONSE FORMATTING
            answer = final_state["generation"]  # Extract response
            print(f"Assistant:\\n{answer}")  # Format for user

# Handler Nodes Pattern (Handler Pattern + Decorator)
# File: src/features/conversation/conversation.py (Line 26-60)
@traceable(run_type="chain", name="Analyze Context for Follow-up")
def analyze_context(state: ConversationalRAGState) -> Dict[str, Any]:
    """Handler: Parse state input â†’ process â†’ return updated state."""
    messages = state["messages"]
    current_question = messages[-1].content if messages else ""

    # Parse + Process
    if len(messages) <= 1:
        is_followup = False
    else:
        # LLM-based analysis (Layer 2 responsibility)
        is_followup = llm_analyze(messages)

    # Return formatted update
    return {"is_followup": is_followup, "question": current_question}

# âœ… PADRÃƒO CORRETO - Session Management (Delegation to Layer 4)
# File: src/core/services/memory_manager.py (Line 90-100)
def get_conversation_config(user_id: str = "default") -> dict:
    """Delegate session retrieval to Layer 4."""
    return conversation_manager.get_config(user_id)

def reset_conversation(user_id: str = "default") -> None:
    """Delegate session reset to Layer 4."""
    conversation_manager.reset_session(user_id)
```

**Fluxo de ComunicaÃ§Ã£o (Layer 1):**

```
â”Œâ”€â”€â”€ User Input (CLI) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                 â”‚
â”œâ”€ Input Parser (Line 60-75)                    â”‚
â”‚  â””â”€ Valida e limpa entrada                    â”‚
â”‚                                                â”‚
â”œâ”€ Command Dispatcher (Line 80-95)              â”‚
â”‚  â”œâ”€ /reset â†’ Layer 4 reset_conversation()    â”‚
â”‚  â”œâ”€ /quit â†’ Exit loop                         â”‚
â”‚  â”œâ”€ /help â†’ Print help                        â”‚
â”‚  â””â”€ question â†’ Layer 2 invocation              â”‚
â”‚                                                â”‚
â”œâ”€ Request Formatter (Line 146-165)             â”‚
â”‚  â””â”€ Convert string â†’ HumanMessage + state    â”‚
â”‚                                                â”‚
â”œâ”€ [Layer 2 Processing] â† Graph invocation      â”‚
â”‚                                                â”‚
â”œâ”€ Response Formatter (Line 205-210)            â”‚
â”‚  â””â”€ Extract generation + format               â”‚
â”‚                                                â”‚
â”œâ”€ [Output] Print formatted response            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Exemplos Reais de CÃ³digo:**

_Exemplo 1: CLI Command Handler (Command Pattern)_

```python
# File: scripts/chat.py (Line 70-100)
if user_input.startswith("/"):
    command = user_input.lower()
    if command in ["/quit", "/exit"]:
        print("\\nğŸ‘‹ Goodbye!")
        break
    elif command == "/reset":
        reset_conversation(user_id)
        config = get_conversation_config(user_id)
        conversation_count = 0
        print("\\nğŸ”„ Conversation reset!")
    elif command == "/help":
        print_help()
    else:
        print(f"âŒ Unknown command: {user_input}")
    continue
```

_Exemplo 2: Question Handler (Orchestration Pattern)_

```python
# File: scripts/chat.py (Line 110-125)
conversation_count += 1
print(f"\\n[Turn {conversation_count}] Processing...\\n")

answer = run_conversational_query(user_input, user_id, config)

print(f"\\n{'='*80}")
print("Assistant:")
print("-" * 80)
print(answer)
print("=" * 80 + "\\n")
```

_Exemplo 3: Handler Node (Handler Pattern + Decorator)_

```python
# File: src/features/conversation/conversation.py (Line 26-60)
@traceable(run_type="chain", name="Analyze Context for Follow-up")
def analyze_context(state: ConversationalRAGState) -> Dict[str, Any]:
    messages = state["messages"]
    current_question = messages[-1].content if messages else ""
    original_question = current_question

    if len(messages) <= 1:
        return {
            "is_followup": False,
            "question": current_question,
            "original_question": original_question,
        }

    # Get recent history
    history_text = "\\n".join([f"{m.type}: {m.content}" for m in messages[-5:]])

    # LLM analysis
    prompt = ChatPromptTemplate.from_template(...)
    response = (prompt | llm).invoke({"history": history_text, "question": current_question})

    return {"is_followup": "sim" in response.content.lower(), "question": current_question}
```

**Constraints & MÃ©tricas (Layer 1):**

```yaml
Performance_Targets:
  Input_Parsing: '< 10ms (regex-based)'
  Command_Dispatch: '< 5ms (dict lookup)'
  State_Formatting: '< 5ms (dict construction)'
  Response_Formatting: '< 50ms (string extraction)'

Layer_1_Boundaries:
  'âœ… Includes': 'CLI parsing, command dispatch, request formatting, response formatting, session mgmt'
  'âŒ Excludes': 'LLM processing, vector search, database ops, reranking'

Dependency_Direction:
  'UP': 'Receives from user/client'
  'DOWN': 'Delegates to Layer 2 (Orchestration)'
  'SIDE': 'Uses Layer 4 (Memory Manager) for sessions'
  'NEVER': 'Circular dependencies, direct Layer 3/4 business logic'
```

#### **2. CAMADA ORQUESTRAÃ‡ÃƒO (Orchestration/Graph Layer)**

```yaml
Responsabilidade: |
  - Definir schema de estado (TypedDict com tipos seguros)
  - Registrar nÃ³s (funÃ§Ãµes como nodes do grafo)
  - Definir arestas (connections entre nÃ³s)
  - Implementar lÃ³gica de roteamento (conditional edges)
  - Compilar grafo em estado mÃ¡quina executÃ¡vel
  - Executar grafo com estado inicial
  - Integrar persistÃªncia (memory/checkpointer)

Conversa_com: |
  - UP: Layer 1 (Orchestrator) via graph.invoke()
  - DOWN: Layer 3 (Node functions) via node registration
  - SIDE: Layer 4 (MemorySaver) via checkpointer

Pattern_Applied: |
  - StateGraph Pattern: Typed state machine assembly
  - Node Composition Pattern: Functions as nodes
  - Conditional Routing Pattern: add_conditional_edges
  - Graph Compilation Pattern: build â†’ execute
  - Memory Integration Pattern: checkpointer + thread_id

Regra_RÃ­gida: |
  - NÃƒO contÃ©m lÃ³gica de negÃ³cio (delegue para Layer 3)
  - DEVE usar TypedDict (performance vs Pydantic)
  - DEVE registrar TODOS os nÃ³s explicitamente
  - DEVE definir TODOS os edges (sem ambiguidade)
  - DEVE compilar grafo UMA VEZ (reutilize instÃ¢ncia)
  - DEVE suportar loop detection (MAX_ITERATIONS)
  - DEVE manter type safety (Literal, Annotated)
```

**Arquivos Implementadores:**

- `src/features/rag/graph_rag.py` - Grafo RAG bÃ¡sico (linhas 1-133)
- `src/features/conversation/conversation_graph.py` - Grafo conversacional (linhas 1-210)
- `src/core/domain/state.py` - DefiniÃ§Ãµes de estado (linhas 1-80)
- `src/core/services/memory_manager.py` - PersistÃªncia (linhas 1-50)

```python
# âœ… PADRÃƒO CORRETO - StateGraph Assembly Pattern

# 1. STATE DEFINITION (Type-safe schema)
# File: src/core/domain/state.py (Lines 20-45)
from typing import TypedDict, Literal, Annotated
from langchain_core.messages import BaseMessage

class RAGState(TypedDict):
    """Typed state for RAG workflow - ensures compile-time safety."""
    question: str
    complexity: Literal["simple", "complex"]  # Enum-like safety
    documents: list  # Retrieved documents
    generation: str  # Generated answer
    quality_score: Annotated[float, Field(ge=0.0, le=1.0)]  # Bounded 0-1
    iterations: Annotated[int, Field(ge=0)]  # Non-negative

class ConversationalRAGState(TypedDict):
    """Extended state with memory for multi-turn conversations."""
    messages: Annotated[Sequence[BaseMessage], add_messages]  # Chat history (reducer)
    question: str
    complexity: Literal["simple", "complex"]
    documents: list
    generation: str
    quality_score: Annotated[float, Field(ge=0.0, le=1.0)]
    iterations: Annotated[int, Field(ge=0)]
    is_followup: bool  # Follow-up detection
    original_question: str  # Raw input

# 2. GRAPH ASSEMBLY (StateGraph construction)
# File: src/features/rag/graph_rag.py (Lines 51-95)
from langgraph.graph import StateGraph, START, END

def create_rag_graph():
    """Creates and compiles RAG workflow state machine."""
    # Initialize with typed state
    workflow = StateGraph(RAGState)

    # Register nodes (Layer 3 functions)
    workflow.add_node("classify", classify_question)
    workflow.add_node("retrieve", retrieve_adaptive)
    workflow.add_node("rerank", rerank_documents)
    workflow.add_node("generate", generate_answer)
    workflow.add_node("validate", validate_quality)
    workflow.add_node("refine", refine_answer)

    # Define edges (connections between nodes)
    workflow.add_edge(START, "classify")  # Entry point
    workflow.add_edge("classify", "retrieve")
    workflow.add_edge("retrieve", "rerank")
    workflow.add_edge("rerank", "generate")
    workflow.add_edge("generate", "validate")

    # Conditional edge (routing logic based on state)
    workflow.add_conditional_edges(
        "validate",  # Source node
        should_refine,  # Routing function
        {"refine": "refine", END: END}  # Options map
    )
    workflow.add_edge("refine", "validate")  # Loop back

    # Compile into executable state machine
    graph = workflow.compile()
    return graph

# 3. CONDITIONAL ROUTING (Decision logic)
# File: src/features/rag/graph_rag.py (Lines 27-45)
def should_refine(state: RAGState) -> str:
    """Routing function: decides if answer needs refinement or exit."""
    quality_score = state.get("quality_score", 0.0)
    iterations = state.get("iterations", 0)

    if quality_score >= 0.7:
        return END  # Quality good - exit

    if iterations >= MAX_ITERATIONS:
        return END  # Max iterations - exit

    return "refine"  # Low quality - refine answer

# 4. GRAPH EXECUTION (State machine invocation)
# File: src/features/rag/graph_rag.py (Lines 96-130)
def run_rag_query(question: str) -> str:
    """Executes RAG query through LangGraph workflow."""
    graph = create_rag_graph()

    # Initialize state (clean slate for each query)
    initial_state = {
        "question": question,
        "complexity": "",
        "documents": [],
        "generation": "",
        "quality_score": 0.0,
        "iterations": 0,
    }

    # Invoke graph (state machine execution)
    final_state = graph.invoke(initial_state)

    # Extract result
    return final_state["generation"]

# 5. MEMORY INTEGRATION (Persistence)
# File: src/features/conversation/conversation_graph.py (Lines 72-140)
from langgraph.checkpoint.memory import MemorySaver

def create_conversational_rag_graph():
    """Creates conversational RAG with memory persistence."""
    workflow = StateGraph(ConversationalRAGState)

    # Add nodes (conversational + RAG)
    workflow.add_node("analyze_context", analyze_context)
    workflow.add_node("expand_question", expand_question)
    workflow.add_node("check_clarification", check_clarification)
    workflow.add_node("classify", classify_question)
    workflow.add_node("retrieve", retrieve_adaptive)
    workflow.add_node("rerank", rerank_documents)
    workflow.add_node("generate", generate_answer)
    workflow.add_node("validate", validate_quality)
    workflow.add_node("refine", refine_answer)

    # Define edges
    workflow.add_edge(START, "analyze_context")
    workflow.add_edge("analyze_context", "expand_question")
    workflow.add_edge("expand_question", "check_clarification")

    # Conditional: proceed or ask clarification
    workflow.add_conditional_edges(
        "check_clarification",
        should_proceed_or_clarify,
        {"classify": "classify", END: END}
    )

    # RAG flow
    workflow.add_edge("classify", "retrieve")
    workflow.add_edge("retrieve", "rerank")
    workflow.add_edge("rerank", "generate")
    workflow.add_edge("generate", "validate")

    # Conditional refinement
    workflow.add_conditional_edges(
        "validate",
        should_refine,
        {"refine": "refine", END: END}
    )
    workflow.add_edge("refine", "validate")

    # Compile WITH memory checkpointer
    memory = get_memory_saver()
    graph = workflow.compile(checkpointer=memory)
    return graph

# 6. EXECUTION WITH PERSISTENCE
# File: src/features/conversation/conversation_graph.py (Lines 146-196)
def run_conversational_query(question: str, user_id: str, config: dict) -> str:
    """Executes conversational query with memory context."""
    graph = create_conversational_rag_graph()

    # Initial state with HumanMessage for chat history
    initial_state = {
        "messages": [HumanMessage(content=question)],
        "question": question,
        "complexity": "",
        "documents": [],
        "generation": "",
        "quality_score": 0.0,
        "iterations": 0,
        "is_followup": False,
        "original_question": question,
    }

    # Invoke WITH config (thread_id for session persistence)
    final_state = graph.invoke(initial_state, config)

    return final_state["generation"]
```

**Fluxo de ComunicaÃ§Ã£o (Layer 2):**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Layer 2: Orchestration â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                â”‚
â”œâ”€ Input from Layer 1 (question, user_id, config)
â”‚                                                â”‚
â”œâ”€ Create StateGraph(ConversationalRAGState)    â”‚
â”‚  â””â”€ Typed schema with 9 fields               â”‚
â”‚                                                â”‚
â”œâ”€ Register Nodes (add_node)                    â”‚
â”‚  â”œâ”€ Conversational: analyze, expand, clarify â”‚
â”‚  â”œâ”€ RAG: classify, retrieve, rerank          â”‚
â”‚  â”œâ”€ Generation: generate, validate, refine  â”‚
â”‚  â””â”€ All imported from Layer 3                â”‚
â”‚                                                â”‚
â”œâ”€ Define Edges (add_edge)                      â”‚
â”‚  â”œâ”€ Simple edges: node â†’ next_node           â”‚
â”‚  â”œâ”€ Conditional edges: state â†’ routing func  â”‚
â”‚  â”œâ”€ Entry point: START â†’ first node          â”‚
â”‚  â””â”€ Exit points: END                          â”‚
â”‚                                                â”‚
â”œâ”€ Conditional Routing (add_conditional_edges) â”‚
â”‚  â”œâ”€ should_proceed_or_clarify()              â”‚
â”‚  â”‚  â””â”€ If needs_clarification â†’ END          â”‚
â”‚  â”‚  â””â”€ Else â†’ continue to RAG               â”‚
â”‚  â””â”€ should_refine()                          â”‚
â”‚     â””â”€ If quality >= 0.7 â†’ END               â”‚
â”‚     â””â”€ If iterations >= MAX â†’ END             â”‚
â”‚     â””â”€ Else â†’ loop to refine                 â”‚
â”‚                                                â”‚
â”œâ”€ Compile Graph (compile)                      â”‚
â”‚  â””â”€ Optional: with checkpointer=MemorySaver  â”‚
â”‚                                                â”‚
â”œâ”€ Execute Graph (invoke)                       â”‚
â”‚  â”œâ”€ Initialize state (empty â†’ pre-filled)   â”‚
â”‚  â”œâ”€ Pass config with thread_id (if memory)   â”‚
â”‚  â”œâ”€ State flows through all nodes            â”‚
â”‚  â”œâ”€ Each node updates specific fields        â”‚
â”‚  â””â”€ Final state returned                      â”‚
â”‚                                                â”‚
â””â”€ Output to Layer 1 (final_state[generation])â”€â”˜
```

**Exemplos Reais de CÃ³digo:**

_Exemplo 1: StateGraph with Typed State_

```python
# File: src/core/domain/state.py (Line 20-45)
class RAGState(TypedDict):
    question: str
    complexity: Literal["simple", "complex"]  # Type-safe enum
    documents: list
    generation: str
    quality_score: Annotated[float, Field(ge=0.0, le=1.0)]  # Bounded
    iterations: Annotated[int, Field(ge=0)]  # Non-negative

# File: src/features/rag/graph_rag.py (Line 51-70)
workflow = StateGraph(RAGState)
workflow.add_node("classify", classify_question)
workflow.add_node("retrieve", retrieve_adaptive)
workflow.add_edge(START, "classify")
workflow.add_edge("classify", "retrieve")
```

_Exemplo 2: Conditional Routing_

```python
# File: src/features/rag/graph_rag.py (Line 27-45)
def should_refine(state: RAGState) -> str:
    quality_score = state.get("quality_score", 0.0)
    iterations = state.get("iterations", 0)
    if quality_score >= 0.7:
        return END
    if iterations >= MAX_ITERATIONS:
        return END
    return "refine"

workflow.add_conditional_edges(
    "validate",
    should_refine,
    {"refine": "refine", END: END}
)
```

_Exemplo 3: Graph Execution_

```python
# File: src/features/rag/graph_rag.py (Line 96-115)
def run_rag_query(question: str) -> str:
    graph = create_rag_graph()
    initial_state = {"question": question, ...}
    final_state = graph.invoke(initial_state)
    return final_state["generation"]
```

_Exemplo 4: Memory Integration_

```python
# File: src/features/conversation/conversation_graph.py (Line 133-140)
memory = get_memory_saver()
graph = workflow.compile(checkpointer=memory)

# File: src/features/conversation/conversation_graph.py (Line 196)
final_state = graph.invoke(initial_state, config)  # config has thread_id
```

**Constraints & MÃ©tricas (Layer 2):**

```yaml
Performance_Targets:
  Graph_Compilation: '< 50ms (once per workflow)'
  State_Initialization: '< 10ms per query'
  Node_Invocation: '< 10ms routing logic'
  Graph_Invocation: '< 100ms total overhead (excludes Layer 3)'

Layer_2_Boundaries:
  'âœ… Includes': 'StateGraph, node registration, edge definition, routing logic, memory integration'
  'âŒ Excludes': 'Individual node business logic, LLM calls, database operations'

Dependency_Direction:
  'UP': 'Receives from Layer 1 (initial state, config)'
  'DOWN': 'Delegates to Layer 3 (node functions)'
  'SIDE': 'Uses Layer 4 (MemorySaver, session config)'
  'NEVER': 'Direct knowledge of UI, business logic, data access'

Type_Safety:
  'TypedDict': 'Compile-time schema validation'
  'Literal': 'Enum-safe values (simple/complex)'
  'Annotated': 'Field constraints (0.0-1.0, ge=0)'
  'Mypy': 'All type hints checked'
```

#### **3. CAMADA LÃ“GICA (Business Logic / RAG Nodes)**

```yaml
Responsabilidade: |
  - Implementar a lÃ³gica de negÃ³cio do fluxo RAG (classificar â†’ recuperar â†’ rerank â†’ gerar â†’ validar â†’ refinar)
  - Converter contratos de estado (TypedDict) em instruÃ§Ãµes para LLMs, vetores e rerankers
  - Orquestrar prompts, thresholds e ajustes de parÃ¢metros especÃ­ficos por tipo de pergunta
  - Aplicar validaÃ§Ã£o de qualidade, loops de refinamento e estratÃ©gias de fallback quando a pontuaÃ§Ã£o Ã© baixa
  - Medir e registrar mÃ©tricas operacionais (scores, tempo de execuÃ§Ã£o, contadores de iteraÃ§Ã£o)
  - Normalizar dados vindos da Camada 4 (FAISS, reranker, settings) antes de repassar Ã  Camada 2

Conversa_com: |
  - UP: Layer 2 (StateGraph) recebe e devolve dicionÃ¡rios parciais de estado
  - DOWN: Layer 4 (FAISS, BGE CrossEncoder, configuration) via wrappers utilitÃ¡rios
  - SIDE: Core Domain (`src/core/domain/state.py`) para contratos tipados e validadores

Pattern_Applied: |
  - Strategy Pattern: cada node encapsula uma estratÃ©gia de processamento independente
  - Repository Pattern: acesso indireto ao FAISS via `FAISS.load_local` com abstraÃ§Ã£o de dados
  - Singleton Pattern: `get_reranker()` carrega uma Ãºnica instÃ¢ncia compartilhada de CrossEncoder
  - Template Method Pattern: prompts padronizados com placeholders definidos em `ChatPromptTemplate`
  - Circuit Breaker / Fallback Pattern: rerankers e refinadores retornam pass-through quando indisponÃ­veis

Regra_RÃ­gida: |
  - Cada funÃ§Ã£o Ã© especialista em UMA tarefa apenas (manter SRP)
  - NÃƒO acessar UI ou orquestraÃ§Ã£o diretamente (comunicaÃ§Ã£o apenas via estado)
  - SEM manipular sessÃ£o persistente (delegar para Camada 4)
  - DEVE retornar apenas diffs de estado (dict parcial) compatÃ­veis com TypedDict
  - DEVE registrar mÃ©tricas/prints controladas para observabilidade
```

**Arquivos Implementadores:**

- `src/features/rag/nodes.py` â€” 6 nÃ³s especializados do pipeline RAG (Linhas 1-210)
- `src/features/reranking/reranker.py` â€” Singleton + estratÃ©gia de reranking (Linhas 1-210)
- `src/core/domain/state.py` â€” Contratos `RAGState` e validadores (Linhas 20-75)
- `tests/unit/test_reranker.py` â€” Cobertura unitÃ¡ria do reranker (Linhas 1-200)

```python
# âœ… PADRÃƒO CORRETO - EspecializaÃ§Ã£o + Strategy Pattern (exemplos reais)

# 1. ClassificaÃ§Ã£o da pergunta (strategy: classificaÃ§Ã£o)
# File: src/features/rag/nodes.py (Linhas 26-64)
@traceable(run_type="chain", name="Classify Question Complexity")
def classify_question(state: RAGState) -> RAGState:
    question = state["question"]
    prompt = ChatPromptTemplate.from_template("Classifique a seguinte pergunta como 'simple' ou 'complex'.\n\n...")
    response = (prompt | llm).invoke({"question": question})
    complexity = response.content.strip().lower()
    if complexity not in ["simple", "complex"]:
        complexity = "complex"
    return {"complexity": complexity}

# 2. RecuperaÃ§Ã£o adaptativa (strategy: retrieval)
# File: src/features/rag/nodes.py (Linhas 68-118)
@traceable(run_type="retriever", name="Adaptive Document Retrieval")
def retrieve_adaptive(state: RAGState) -> RAGState:
    question = state["question"]
    complexity = state["complexity"]
    k = 10 if complexity == "simple" else 15 if settings.reranker_enabled else (3 if complexity == "simple" else 7)
    vectordb = FAISS.load_local(db_path, embeddings, allow_dangerous_deserialization=True)
    docs = vectordb.similarity_search(question, k=k)
    documents = [doc.page_content for doc in docs]
    return {"documents": documents}

# 3. Reranking BGE (strategy: reranker com fallback)
# File: src/features/rag/nodes.py (Linhas 120-185)
@traceable(run_type="chain", name="BGE Semantic Reranking")
def rerank_documents(state: RAGState) -> RAGState:
    if not settings.reranker_enabled or not state["documents"]:
        return {}
    reranker = get_reranker()
    if reranker is None:
        return {}
    doc_objects = [Document(page_content=doc) for doc in state["documents"]]
    top_n = 5 if state["complexity"] == "simple" else 7
    original_top_n = reranker.top_n
    reranker.top_n = top_n
    reranked_docs = reranker.compress_documents(doc_objects, state["question"])
    reranker.top_n = original_top_n
    return {"documents": [doc.page_content for doc in reranked_docs]}

# 4. GeraÃ§Ã£o de respostas (strategy: generation)
# File: src/features/rag/nodes.py (Linhas 187-228)
@traceable(run_type="llm", name="Generate Answer")
def generate_answer(state: RAGState) -> RAGState:
    contexto = "\n\n".join([f"Documento {i+1}: {doc}" for i, doc in enumerate(state["documents"])])
    prompt = ChatPromptTemplate.from_template("VocÃª Ã© um assistente especializado em responder perguntas ...")
    generation = (prompt | llm).invoke({"contexto": contexto, "pergunta": state["question"]}).content
    return {"generation": generation}

# 5. ValidaÃ§Ã£o de qualidade (strategy: quality gate)
# File: src/features/rag/nodes.py (Linhas 230-272)
@traceable(run_type="chain", name="Validate Answer Quality")
def validate_quality(state: RAGState) -> RAGState:
    prompt = ChatPromptTemplate.from_template("Avalie a qualidade da resposta abaixo em uma escala de 0 a 1.\n\n...")
    response = (prompt | llm).invoke({
        "question": state["question"],
        "contexto": "\n".join(state["documents"][:3]),
        "generation": state["generation"],
    })
    try:
        quality_score = float(response.content.strip())
        quality_score = max(0.0, min(1.0, quality_score))
    except ValueError:
        quality_score = 0.6
    return {"quality_score": quality_score}

# 6. Refinamento iterativo (strategy: refinement loop)
# File: src/features/rag/nodes.py (Linhas 274-323)
@traceable(run_type="chain", name="Refine Answer with Feedback")
def refine_answer(state: RAGState) -> RAGState:
    prompt = ChatPromptTemplate.from_template("VocÃª precisa MELHORAR a resposta anterior que recebeu score de qualidade {score:.2f}.\n\n...")
    refined = (prompt | llm).invoke({
        "score": state["quality_score"],
        "previous": state["generation"],
        "contexto": "\n\n".join([f"Documento {i+1}: {doc}" for i, doc in enumerate(state["documents"])]) ,
        "pergunta": state["question"],
    }).content
    return {"generation": refined, "iterations": state.get("iterations", 0) + 1}

# 7. Singleton do reranker (strategy provider)
# File: src/features/reranking/reranker.py (Linhas 32-120)
@traceable(run_type="tool", name="Load BGE Reranker Model")
def get_reranker() -> Optional[CrossEncoder]:
    global _reranker_instance
    if not settings.reranker_enabled:
        return None
    if _reranker_instance is None:
        _reranker_instance = CrossEncoder(settings.reranker_model, activation_fn=torch.nn.Sigmoid())
    return _reranker_instance

# 8. Threshold + top-N filtering (business rule)
# File: src/features/reranking/reranker.py (Linhas 122-220)
@traceable(run_type="chain", name="BGE Semantic Reranking with Threshold")
def rerank_documents(query: str, documents: List[str], top_n: Optional[int] = None) -> List[str]:
    reranker = get_reranker()
    if reranker is None or not documents:
        return documents
    effective_top_n = top_n if top_n is not None else settings.reranker_top_n
    scores = reranker.predict([(query, doc) for doc in documents])
    threshold = settings.reranker_score_threshold
    mask = scores >= threshold if threshold > 0 else np.ones_like(scores, dtype=bool)
    filtered_docs = [doc for doc, keep in zip(documents, mask) if keep]
    if not filtered_docs:
        best_idx = int(np.argmax(scores))
        return [documents[best_idx]]
    sorted_indices = np.argsort(scores[mask])[::-1][:effective_top_n]
    return [filtered_docs[i] for i in sorted_indices]
```

**Contrato de Estado & EspecializaÃ§Ã£o**

- `RAGState` e `ConversationalRAGState` (src/core/domain/state.py, Linhas 20-75) definem campos obrigatÃ³rios e limites (`Literal`, `Annotated`) consumidos por todos os nodes.
- Cada node recebe `state: RAGState` e retorna apenas as chaves que modifica, mantendo imutabilidade parcial e isolamento.
- A Camada 2 cuida da fusÃ£o (`state.update(node_result)`) garantindo que nenhuma funÃ§Ã£o escreva em campos que nÃ£o controla.

**Pipeline Camada 3 (PseudocÃ³digo)**

```python
def business_logic_pipeline(question: str) -> str:
    state = {"question": question, "documents": [], "iterations": 0}
    state |= classify_question(state)
    state |= retrieve_adaptive(state)
    state |= rerank_documents(state)
    state |= generate_answer(state)
    state |= validate_quality(state)
    while state["quality_score"] < 0.7 and state["iterations"] < MAX_ITERATIONS:
        state |= refine_answer(state)
        state |= validate_quality(state)
    return state["generation"]
```

**Fluxo Camada 3 (ASCII)**

```
[Layer 2] â†’ classify_question â†’ retrieve_adaptive â†’ (optional) rerank_documents â†’
    generate_answer â†’ validate_quality â†’ [score >= 0.7?]
        â”œâ”€ Sim â†’ retorna geraÃ§Ã£o final para Layer 2
        â””â”€ NÃ£o â†’ refine_answer â†’ validate_quality (loop atÃ© score â‰¥ 0.7 ou iterations â‰¥ 2)
           â””â”€ Se atingir limite â†’ devolve melhor geraÃ§Ã£o disponÃ­vel com flag de baixa qualidade
```

**MÃ©tricas & Limites (Business Logic)**

```yaml
Quality_Gates:
  Minimum_Quality_Score: '>= 0.70 (validado por validate_quality)'
  Max_Iterations: '2 (evita loops infinitos em refine_answer)'
  Retrieval_Docs:
    Simple: 'k=10 (rerank) ou 3 (sem rerank)'
    Complex: 'k=15 (rerank) ou 7 (sem rerank)'
  Reranker_Top_N:
    Simple: '5 documentos'
    Complex: '7 documentos'
  Threshold_Default: 'settings.reranker_score_threshold (0.0 â†’ sem filtro)'
Performance_Targets:
  classify_question: '< 400ms (LLM curto)'
  retrieve_adaptive: '< 150ms (FAISS local)'
  rerank_documents: '< 250ms (top-15 â†’ top-7)'
  generate_answer: '< 2.5s (LLM principal)'
  validate_quality: '< 1.5s (LLM judge)'
  refine_answer: '< 2.5s (LLM com feedback)'
Observability:
  Traceable_Decorators: '100% dos nodes possuem @traceable'
  Logging: 'Structured logs via structlog (reranker, thresholds, tempos)'
```

**Testes Essenciais (Cobertura atual)**

- `tests/unit/test_reranker.py` â€” valida singleton, top-N, threshold, fallback e conversÃµes de documentos.
- `tests/unit/test_threshold_filtering.py` â€” garante estatÃ­sticas de corte e distribuiÃ§Ã£o de scores.
- `tests/unit/test_threshold_performance.py` â€” mede tempo de reranking e garante cumprimento dos SLAs.
- `tests/unit/test_threshold_real_world_integration.py` â€” cenÃ¡rios reais com scores variados.
- `tests/unit/test_state_types.py` â€” confirma contrato de TypedDict para todos os campos usados pelos nodes.

**Checklist de ValidaÃ§Ã£o antes do Deploy**

1. âœ… Todos os nodes retornam apenas campos declarados em `RAGState`/`ConversationalRAGState`.
2. âœ… Threshold e top_n configurados via `settings` (sem valores mÃ¡gicos no cÃ³digo).
3. âœ… Reranker carrega uma Ãºnica vez (`get_reranker` + `reset_reranker` para testes).
4. âœ… Logs e traces ativos para cada node (`@traceable`).
5. âœ… Testes unitÃ¡rios mencionados executados e passando.
6. âœ… MÃ©tricas (tempo, score) monitoradas via LangSmith e logs estruturados.
7. âœ… Fallbacks funcionando (quando reranker desabilitado ou sem documentos).

**Limites e Fronteiras**

- Inclui: prompts, heurÃ­sticas, thresholds, manipulaÃ§Ã£o de documentos, cÃ¡lculos de score, loops de refinamento.
- Exclui: definiÃ§Ã£o do grafo (Layer 2), gerenciamento de sessÃµes (Layer 4), UI/IO (Layer 1).
- Qualquer novo algoritmo â†’ implementar como novo node seguindo Strategy Pattern e adicionar testes dedicados.

#### **4. CAMADA ESPECIALIZADA**

```yaml
Responsabilidade: |
  - Fornecer serviÃ§os tÃ©cnicos especializados (configuraÃ§Ã£o, logging estruturado,
      vetores FAISS, LangSmith, memÃ³ria de sessÃ£o, reranker BGE)
  - Encapsular integraÃ§Ãµes externas em contratos estÃ¡veis (adapters/facades)
  - Garantir validaÃ§Ã£o, observabilidade, seguranÃ§a e performance de recursos crÃ­ticos
  - Disponibilizar utilitÃ¡rios resilientes para consumo da Camada 3 sem vazar detalhes

Conversa_com: |
  - UP: Nenhuma (nÃ£o conhece quem consome)
  - DOWN: ServiÃ§os externos (LangSmith, FAISS, Torch, ambientes, FS)
  - SIDE: Bibliotecas utilitÃ¡rias (structlog, pydantic, langgraph)
  - EXPÃ•E: FunÃ§Ãµes/helpers sÃ­ncro-nos para Camada 3 consumir via importaÃ§Ã£o

Pattern_Applied: |
  - Adapter Pattern: `monitoring.get_langsmith_client`, `memory_manager.ConversationManager`
  - Facade Pattern: `logging.configure_logging` + `get_logger`
  - Provider/Singleton Pattern: `reranking.get_reranker`
  - Configuration as Code: `Settings(BaseSettings)`

Regra_RÃ­gida: |
  - NÃƒO conhecem quem os usa - apenas fornecem serviÃ§os (contratos estÃ¡veis)
  - NÃƒO devem importar camadas superiores (Presentation, Orchestration, Business)
  - DEVEM validar entradas e falhas externas antes de retornar
  - DEVEM ser observÃ¡veis (logs, mÃ©tricas) e resilientes (fallbacks)
```

**PropÃ³sito da camada:** Consolidar toda dependÃªncia especializada (APIs externas, recursos
de infraestrutura, validaÃ§Ã£o de ambiente) em mÃ³dulos dedicados que podem ser
reutilizados por qualquer fluxo da aplicaÃ§Ã£o sem acoplar a lÃ³gica de negÃ³cio. A camada
atua como fronteira com o mundo externo, garantindo contratos estÃ¡veis, validaÃ§Ã£o
fail-fast e observabilidade consistente.

**Arquivos Implementadores:**

- `src/infrastructure/config/settings.py` â€” `Settings(BaseSettings)` com validaÃ§Ã£o
  estrita (linhas 1-95)
- `src/infrastructure/logging/logger.py` â€” ConfiguraÃ§Ã£o `structlog` + `get_logger`
  (linhas 1-180)
- `src/core/services/memory_manager.py` â€” `ConversationManager` (MemorySaver) e
  helpers (linhas 1-140)
- `src/core/services/monitoring.py` â€” Adapter LangSmith + tratamento de erros
  estruturados (linhas 1-200)
- `src/features/reranking/reranker.py` â€” Provider do CrossEncoder BGE e filtros
  semÃ¢nticos (linhas 1-220)
- `src/features/rag/nodes.py` â€” Uso indireto de FAISS via `FAISS.load_local(...)`
  (linhas 70-110) consumindo serviÃ§os expostos por esta camada

```python
# âœ… CONFIGURAÃ‡ÃƒO CENTRALIZADA (Settings + validaÃ§Ã£o fail-fast)
# File: src/infrastructure/config/settings.py (Linhas 18-95)
class Settings(BaseSettings):
        langsmith_api_key: str = Field(..., description="LangSmith API Key")
        google_api_key: str = Field(..., description="Google Gemini API Key")
        llm_model: str = Field(default="gemini-2.0-flash-exp")
        reranker_enabled: bool = Field(default=True)
        reranker_model: str = Field(default="BAAI/bge-reranker-base")
        log_level: str = Field(default="INFO")
        log_format: str = Field(default="auto")

settings = Settings()  # InstÃ¢ncia Ãºnica validada no import

# âœ… FACADE PARA LOGGING ESTRUTURADO (structlog + auto formataÃ§Ã£o)
# File: src/infrastructure/logging/logger.py (Linhas 35-160)
def configure_logging() -> None:
        shared_processors = [
                structlog.contextvars.merge_contextvars,
                structlog.processors.add_log_level,
                structlog.processors.format_exc_info,
                structlog.processors.TimeStamper(fmt="iso", utc=True),
                structlog.processors.CallsiteParameterAdder({...}),
        ]
        if settings.log_format.lower() == "json":
                processors = shared_processors + [json_renderer]
        elif settings.log_format.lower() == "console":
                processors = shared_processors + [structlog.dev.ConsoleRenderer(colors=True)]
        else:
                processors = shared_processors + ([structlog.dev.ConsoleRenderer(colors=True)]
                                                                                    if sys.stderr.isatty() else [json_renderer])
        log_level = getattr(logging, settings.log_level.upper(), logging.INFO)
        structlog.configure(
            cache_logger_on_first_use=True,
            wrapper_class=structlog.make_filtering_bound_logger(log_level),
            processors=processors,
            logger_factory=structlog.PrintLoggerFactory(file=sys.stdout),
        )

# âœ… ADAPTER DE MEMÃ“RIA (MemorySaver + sessÃµes isoladas)
# File: src/core/services/memory_manager.py (Linhas 10-110)
class ConversationManager:
        def __init__(self):
                self.memory = MemorySaver()
                self.active_sessions: Dict[str, str] = {}

        def get_config(self, user_id: str = "default") -> dict:
                thread_id = self.get_or_create_session(user_id)
                return {"configurable": {"thread_id": thread_id}}

conversation_manager = ConversationManager()

# âœ… PROVIDER DO RERANKER (lazy load + fallback)
# File: src/features/reranking/reranker.py (Linhas 32-145)
@traceable(run_type="tool", name="Load BGE Reranker Model")
def get_reranker() -> Optional[CrossEncoder]:
        global _reranker_instance
        if not settings.reranker_enabled:
                return None
        if _reranker_instance is None:
                _reranker_instance = CrossEncoder(
                        settings.reranker_model,
                        activation_fn=torch.nn.Sigmoid(),
                )
        return _reranker_instance

# âœ… ADAPTER LANGSMITH (observabilidade externa)
# File: src/core/services/monitoring.py (Linhas 25-120)
def list_recent_runs(limit: int = 10) -> List:
        try:
                client = get_langsmith_client()
                runs = list(client.list_runs(project_name=settings.langsmith_project, limit=limit))
                return runs
        except Exception as e:
                logger.error(
                        "error_listing_runs",
                        project_name=settings.langsmith_project,
                        error_type=type(e).__name__,
                        error_message=str(e),
                        exc_info=True,
                )
                return []
```

**Fluxo Camada 4 (Consumo pela Camada 3):**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Layer 3 (Nodes/RAG) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                  â”‚
â”‚  retrieve_adaptive â†’ FAISS.load_local() â”€â”       â”‚
â”‚  rerank_documents â†’ get_reranker() â”€â”€â”€â”€â”€â”¤       â”‚
â”‚  validate_quality â†’ settings.* configs â”€â”¤       â”‚
â”‚  analyze_context â†’ get_logger() â”€â”€â”€â”€â”€â”€â”€â”€â”¤       â”‚
â”‚  run_graph(...) â†’ get_memory_saver() â”€â”€â”€â”˜       â”‚
â”‚                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Layer 4 (Infra Services) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚            â”‚             â”‚             â”‚
                     â”‚            â”‚             â”‚             â”‚
         FAISS Index   BGE CrossEncoder   LangSmith API  Pydantic Settings
                     â”‚            â”‚             â”‚             â”‚
                (Disco)      (Torch)        (HTTP)       (.env â†’ validaÃ§Ã£o)
```

**MÃ©tricas & Limites (Camada 4):**

```yaml
Performance_Targets:
  Settings_Load: '< 15ms (validaÃ§Ã£o BaseSettings)'
  Logging_Configuration: '< 30ms (structlog configure)'
  Reranker_First_Load: '< 3.5s (download/carregar modelo BGE)'
  Reranker_Subsequent: '< 5ms (instÃ¢ncia cacheada)'
  Memory_Config_Fetch: '< 2ms (dict simples com thread_id)'
  LangSmith_ListRuns: '< 1.2s (timeout configurado pelo client)'

ResiliÃªncia_Falhas:
  Reranker_Disabled: 'Retorna pass-through sem quebrar pipeline'
  LangSmith_Error: 'Log estruturado + [] (fallback seguro)'
  Settings_Invalid: 'Falha no import (fail-fast) -> impedir boot inseguro'
  FAISS_Load: 'Requer allow_dangerous_deserialization=True â†’ validar Ã­ndice confiÃ¡vel'

SeguranÃ§a:
  Secrets: 'Nunca logar API keys; usar Pydantic para validaÃ§Ã£o'
  IO: 'Carregar Ã­ndices FAISS apenas de diretÃ³rios versionados (./banco_faiss/)'
  Observabilidade: 'Logs JSON incluem correlation ids via contextvars'
```

**Testes Essenciais & Cobertura:**

- `tests/unit/test_settings.py` â€” valida defaults, obrigatoriedade de API keys e
  serializaÃ§Ã£o
- `tests/unit/test_logging.py` â€” garante formatos JSON/console e performance
- `tests/unit/test_session_config.py` â€” assegura `thread_id` Ãºnico por usuÃ¡rio
- `tests/unit/test_reranker.py` + `tests/unit/test_threshold_*` â€” validam singleton,
  thresholds e fallback do reranker
- `tests/unit/test_state_types.py` â€” garante compatibilidade dos contratos com o
  consumo da Camada 3

**Checklist de ValidaÃ§Ã£o Camada 4:**

1. âœ… `settings` carregado sem exceÃ§Ãµes (env vÃ¡lido) antes de iniciar aplicaÃ§Ã£o
2. âœ… `configure_logging()` executado uma vez e `get_logger` usado em todos adapters
3. âœ… `ConversationManager` expÃµe apenas dicts (`thread_id`) para LangGraph
4. âœ… `get_reranker()` suporta primeira carga lenta, demais instantÃ¢neas
5. âœ… `FAISS.load_local` documentado com requisito de Ã­ndices confiÃ¡veis
6. âœ… Falhas externas (LangSmith, FAISS, Torch) sÃ£o logadas e retornam fallback seguro

> ğŸ” **Nota:** Caso novos serviÃ§os especializados sejam adicionados (cache Redis,
> webhooks, filas), manter o mesmo contrato: mÃ³dulo isolado, sem imports para camadas
> superiores e com testes unitÃ¡rios dedicados que comprovem resiliÃªncia.

### ğŸ“Š InventÃ¡rio estruturado (Atende T-20)

**Controllers / Handlers (5+):**

- `scripts/chat.py::run_interactive_conversation` â€” loop CLI principal com dispatch de comandos (/reset, /help, /quit).
- `scripts/chat.py::print_header` â€” controller de apresentaÃ§Ã£o, inicializa instruÃ§Ãµes e branding.
- `scripts/chat.py::print_help` â€” endpoint de ajuda exposto via `/help`.
- `src/features/conversation/conversation_graph.py::run_conversational_query` â€” faÃ§ade orquestradora chamada pela CLI (entrada/saÃ­da de Layer 1).
- `src/features/conversation/conversation.py::{analyze_context, expand_question, check_clarification}` â€” tratadores de entrada responsÃ¡veis por preparar o estado antes da Layer 2.

**Services / Business Logic (5+):**

- `src/features/rag/nodes.py::classify_question`
- `src/features/rag/nodes.py::retrieve_adaptive`
- `src/features/rag/nodes.py::rerank_documents`
- `src/features/rag/nodes.py::generate_answer`
- `src/features/rag/nodes.py::validate_quality`
- `src/features/rag/nodes.py::refine_answer`

**Repositories / Data Access (5+):**

- `src/core/services/memory_manager.py::ConversationManager.get_or_create_session` â€” provÃª `thread_id` persistente via MemorySaver.
- `src/core/services/memory_manager.py::get_memory_saver` â€” expÃµe storage LangGraph para camadas superiores.
- `src/features/reranking/reranker.py::get_reranker` â€” gerencia lifecycle do CrossEncoder (carregamento e caching).
- `src/features/reranking/reranker.py::rerank_documents` â€” aplica threshold/ordenaÃ§Ã£o e devolve subconjuntos (dados prontos para consumo).
- `src/core/services/monitoring.py::list_recent_runs` â€” consulta LangSmith e retorna coleÃ§Ãµes de runs/tags para diagnÃ³stico.

**Domain Entities / Contracts (3+):**

- `src/core/domain/session.py::SessionConfig` â€” entidade imutÃ¡vel que descreve parÃ¢metros de sessÃ£o.
- `src/core/domain/state.py::RAGState`
- `src/core/domain/state.py::ConversationalRAGState`
- `src/infrastructure/config/settings.py::Settings` â€” agregado de configuraÃ§Ã£o com validaÃ§Ã£o automÃ¡tica.

---

### âœ… **LINGUAGEM UNIVERSAL: **

#### **PADRÃƒO DE COMUNICAÃ‡ÃƒO**

```yaml
Regra_Absoluta: 'Cada camada sÃ³ conversa com a imediatamente inferior por meio de contratos estÃ¡veis; Layer 4 nunca chama Layers 1-3.'
BenefÃ­cio: |
  - Evita dependÃªncias circulares e facilita auditorias de seguranÃ§a
  - Permite substituir infraestrutura (FAISS, LangSmith) sem alterar camadas superiores
  - Simplifica testes ao permitir mocks por camada
  - MantÃ©m mensagens de observabilidade consistentes em todo o stack
```

```python
from langchain_community.vectorstores import FAISS
from langsmith import traceable

from src.core.domain.state import RAGState
from src.core.services.memory_manager import get_conversation_config  # Layer 4
from src.features.conversation.conversation_graph import create_conversational_rag_graph  # Layer 2
from src.features.rag.nodes import embeddings, db_path, retrieve_adaptive  # Layer 3


def cli_loop(user_id: str = "cli_user") -> None:
  config = get_conversation_config(user_id)          # Layer 1 â†’ Layer 4 (session)
  graph = create_conversational_rag_graph()          # Layer 1 â†’ Layer 2 (orquestraÃ§Ã£o)
  state = {
      "messages": [],
      "question": "OlÃ¡",
      "complexity": "simple",
      "documents": [],
      "generation": "",
      "quality_score": 0.0,
      "iterations": 0,
  }
  final_state = graph.invoke(state, config)          # Layer 2 chama apenas nodes da Layer 3
  print(final_state["generation"])                  # Layer 1 apresenta resposta


@traceable(run_type="retriever", name="Adaptive Document Retrieval")
def retrieve_adaptive(state: RAGState) -> RAGState:
  vectordb = FAISS.load_local(db_path, embeddings, allow_dangerous_deserialization=True)  # Layer 3 â†’ Layer 4
  docs = vectordb.similarity_search(state["question"], k=10)
  return {"documents": [doc.page_content for doc in docs]}


# Qualquer tentativa de Layer 4 acessar Layer 1 dispara alerta de lint/pipeline.
```

#### **THREAD-SAFETY E VALIDAÃ‡ÃƒO EMPRESARIAL**

```python
from threading import Lock
from typing import Any, Optional
from uuid import uuid4

from structlog import get_logger

from src.core.domain.session import SessionConfig
from src.features.reranking.reranker import get_reranker


logger = get_logger(__name__)


class ThreadSafeRerankerPool:
  """Garante instÃ¢ncia Ãºnica do CrossEncoder mesmo em cenÃ¡rios multi-thread."""

  _instance: Optional[Any] = None
  _lock = Lock()

  @classmethod
  def acquire(cls) -> Optional[Any]:
    with cls._lock:  # ğŸ”’ evita corrida durante o download do modelo
      if cls._instance is None:
        cls._instance = get_reranker()
      return cls._instance


def build_session_config(max_turns: int = 10, memory_window: int = 6) -> SessionConfig:
  """ValidaÃ§Ã£o empresarial usando Pydantic antes de expor configuraÃ§Ã£o a outras camadas."""

  try:
    config = SessionConfig(thread_id=uuid4(), max_turns=max_turns, memory_window=memory_window)
    logger.info("session_config_ready", thread_id=str(config.thread_id), max_turns=config.max_turns)
    return config
  except ValueError as exc:
    logger.error("session_config_invalid", error=str(exc), max_turns=max_turns, memory_window=memory_window)
    raise


# Uso combinado: Layer 4 monta dependÃªncias thread-safe e validadas antes de entregÃ¡-las Ã s camadas superiores.
```

---

### âœ… **PADRÃ•ES ENTERPRISE IMPLEMENTADOS**

#### **1. STRATEGY PATTERN (ObrigatÃ³rio para Algoritmos)**

- **Objetivo:** Desacoplar heurÃ­sticas de RAG para permitir troca dinÃ¢mica sem alterar a orquestraÃ§Ã£o.
- **Uso real:** `src/features/rag/nodes.py` (cada node Ã© uma estratÃ©gia independente) e `src/features/reranking/reranker.py` (CrossEncoder BGE plugÃ¡vel).

```python
# ğŸš« ERRADO - if/else diretamente no node (dificulta novos algoritmos)
def rerank_documents(state: RAGState) -> RAGState:
  provider = settings.reranker_provider  # valor imaginÃ¡rio
  if provider == "bge":
    return _rerank_with_bge(state)
  if provider == "bm25":
    return _rerank_with_bm25(state)
  return {}


# âœ… CORRETO - estratÃ©gias intercambiÃ¡veis com contrato explÃ­cito
from abc import ABC, abstractmethod
from typing import List

from langchain_core.documents import Document

from config.settings import settings
from src.core.domain.state import RAGState
from src.features.reranking.reranker import get_reranker


class RerankingStrategy(ABC):
  @abstractmethod
  def rerank(self, question: str, documents: List[str]) -> List[str]: ...


class BgeCrossEncoderStrategy(RerankingStrategy):
  def __init__(self) -> None:
    self._model = get_reranker()  # src/features/reranking/reranker.py

  def rerank(self, question: str, documents: List[str]) -> List[str]:
    if self._model is None:
      return documents
    doc_objects = [Document(page_content=d) for d in documents]
    return [doc.page_content for doc in self._model.compress_documents(doc_objects, question)]


class PassThroughStrategy(RerankingStrategy):
  def rerank(self, question: str, documents: List[str]) -> List[str]:
    return documents


class RerankingEngine:
  def __init__(self, strategy: RerankingStrategy) -> None:
    self._strategy = strategy

  def execute(self, question: str, documents: List[str]) -> List[str]:
    return self._strategy.rerank(question, documents)


def build_reranking_engine() -> RerankingEngine:
  strategy: RerankingStrategy = BgeCrossEncoderStrategy() if settings.reranker_enabled else PassThroughStrategy()
  return RerankingEngine(strategy)


def rerank_documents(state: RAGState) -> RAGState:
  engine = build_reranking_engine()
  reranked = engine.execute(state["question"], state["documents"])
  return {"documents": reranked}
```

- **BenefÃ­cios comprovados:**
  - Testes independentes por estratÃ©gia (`tests/unit/test_reranker.py`).
  - Toggle em runtime via `settings.reranker_enabled` sem alterar `graph_rag.py`.
  - Facilita adicionar novos rerankers hÃ­bridos sem quebrar camadas superiores.

#### **2. DEPENDENCY INJECTION (ObrigatÃ³rio para Gerentes)**

- **Objetivo:** Inverter o controle para que serviÃ§os de camada superior operem sobre contratos, mantendo infraestrutura plugÃ¡vel.
- **Uso real:**
  - `create_conversational_rag_graph()` recebe `MemorySaver` via `checkpointer=memory` (injeÃ§Ã£o pela Camada 4).
  - `scripts/chat.py` injeta `config` obtida de `get_conversation_config()` antes de chamar Layer 2.

```python
# ğŸš« ERRADO - ServiÃ§o cria dependÃªncias internas (dificulta testes e troca de providers)
class RagController:
  def answer(self, question: str) -> str:
    vectordb = FAISS.load_local(db_path, embeddings)
    reranker = get_reranker()
    docs = vectordb.similarity_search(question)
    return generate_answer({"question": question, "documents": [d.page_content for d in docs]})["generation"]


# âœ… CORRETO - DependÃªncias entram pelo construtor (injeÃ§Ã£o explÃ­cita + fÃ¡cil de mockar)
from dataclasses import dataclass
from typing import Protocol

from langchain_community.vectorstores import FAISS
from langchain_core.documents import Document

from src.features.rag.nodes import db_path, embeddings, generate_answer, retrieve_adaptive
from src.features.reranking.reranker import get_reranker


class RetrievalStrategy(Protocol):
  def __call__(self, question: str) -> list[str]: ...


class RerankingStrategy(Protocol):
  def __call__(self, question: str, documents: list[str]) -> list[str]: ...


class GenerationStrategy(Protocol):
  def __call__(self, question: str, documents: list[str]) -> str: ...


@dataclass(slots=True)
class RagService:
  retrieve: RetrievalStrategy
  rerank: RerankingStrategy
  generate: GenerationStrategy

  def run(self, question: str) -> str:
    documents = self.retrieve(question)
    reranked = self.rerank(question, documents)
    return self.generate(question, reranked)


# Layer 4 efetua o wiring com adapters existentes
def _retrieve_documents(question: str) -> list[str]:
  state = {"question": question, "complexity": "simple", "documents": []}
  return retrieve_adaptive(state)["documents"]


def _rerank_with_bge(question: str, documents: list[str]) -> list[str]:
  model = get_reranker()
  if model is None:
    return documents
  doc_objects = [Document(page_content=d) for d in documents]
  return [doc.page_content for doc in model.compress_documents(doc_objects, question)]


def _generate_answer(question: str, documents: list[str]) -> str:
  return generate_answer({"question": question, "documents": documents})["generation"]


rag_service = RagService(
  retrieve=_retrieve_documents,
  rerank=_rerank_with_bge,
  generate=_generate_answer,
)


def handle_question(question: str, *, service: RagService = rag_service) -> str:
  """Camada 1 consome serviÃ§o prÃ©-configurado; testes podem injetar mock."""
  return service.run(question)
```

- **BenefÃ­cios comprovados:**
  - Permite substituir implementaÃ§Ãµes em testes/unit (mocks de retriever e reranker).
  - Evita instanciar recursos pesados repetidamente (CrossEncoder, FAISS).
  - Torna explÃ­cito quais dependÃªncias cada serviÃ§o precisa, reduzindo acoplamento oculto.

#### **3. EXCEPTION HIERARCHY (ObrigatÃ³rio para Erros)**

- **Objetivo:** Unificar tratamento de erros, garantindo logs estruturados e propagaÃ§Ã£o coerente entre as camadas.
- **Hierarquia Recomendada:**
  - `BaseProjectError(Exception)` â†’ raiz para todo erro do projeto (localizada em `src/shared/exceptions.py`).
  - `InfrastructureError(BaseProjectError)` â†’ falhas Layer 4 (FAISS, LangSmith, MemorySaver, rede).
  - `BusinessRuleViolation(BaseProjectError)` â†’ inconsistÃªncias Layer 3 (ex.: score invÃ¡lido, ausÃªncia de documentos).
  - `OrchestrationError(BaseProjectError)` â†’ erros de ligaÃ§Ã£o na Layer 2 (state graph, config faltante).
  - `PresentationError(BaseProjectError)` â†’ I/O invÃ¡lido na Layer 1 (comandos CLI, payload HTTP).
  - _Nota:_ centralizar a hierarquia em `src/shared/exceptions.py` (criar o mÃ³dulo caso nÃ£o exista) para evitar duplicaÃ§Ã£o entre camadas.

```python
# ğŸš« ERRADO - Captura genÃ©rica e silÃªncio (perde contexto e dificulta observabilidade)
def list_recent_runs(limit: int = 10) -> list:
  try:
    client = get_langsmith_client()
    return list(client.list_runs(project_name=settings.langsmith_project, limit=limit))
  except Exception:
    return []  # Swallow: quem chama nÃ£o sabe o que ocorreu


# âœ… CORRETO - Hierarquia explÃ­cita + log estruturado + rethrow contextualizado
import structlog

from config.settings import settings
from src.core.services.memory_manager import get_conversation_config
from src.core.services.monitoring import get_langsmith_client
from src.features.conversation.conversation_graph import create_conversational_rag_graph
from src.shared.exceptions import BaseProjectError, InfrastructureError, OrchestrationError, PresentationError

logger = structlog.get_logger(__name__)


def list_recent_runs(limit: int = 10) -> list:
  try:
    client = get_langsmith_client()
    return list(client.list_runs(project_name=settings.langsmith_project, limit=limit))
  except BaseProjectError:  # JÃ¡ tratado em camada inferior (nÃ£o duplicar log)
    raise
  except Exception as exc:  # Erro inesperado â†’ empacotar como InfrastructureError
    logger.error(
      "langsmith_runs_error",
      error_type=type(exc).__name__,
      error_message=str(exc),
      limit=limit,
      exc_info=True,
    )
    raise InfrastructureError("Failed to list LangSmith runs") from exc


# Layer 2 decide se converte para OrchestrationError ou propaga para Layer 1
def run_conversational_query(question: str, user_id: str, config: dict) -> str:
  try:
    graph = create_conversational_rag_graph()
    state = {
      "messages": [],
      "question": question,
      "complexity": "simple",
      "documents": [],
      "generation": "",
      "quality_score": 0.0,
      "iterations": 0,
    }
    final_state = graph.invoke(state, config)
    return final_state["generation"]
  except InfrastructureError as exc:  # jÃ¡ logado em Layer 4
    raise OrchestrationError("External dependency unavailable") from exc
  except Exception as exc:
    logger.error("graph_invoke_error", user_id=user_id, exc_info=True)
    raise OrchestrationError("Failure during graph execution") from exc


# Layer 1 converte para resposta amigÃ¡vel mantendo rastreabilidade
def handle_cli(question: str, user_id: str = "cli_user") -> None:
  try:
    answer = run_conversational_query(question, user_id, get_conversation_config(user_id))
    print(answer)
  except OrchestrationError as exc:
    print("âš ï¸  NÃ£o foi possÃ­vel concluir a conversa agora. Consulte os logs." )
    raise PresentationError("Conversation aborted") from exc
```

- **Diretrizes:**
  - Logs devem usar `exc_info=True` e campos estruturados (`error_type`, `error_message`, `dependency`).
  - Somente a camada que adiciona contexto loga; camadas superiores reempacotam sem duplicar logs.
  - `BaseProjectError` (e derivados) SEMPRE devem ser propagados intactos para preservar o encadeamento.
  - ExceÃ§Ãµes de validaÃ§Ã£o (`ValueError`, `ValidationError`) devem ser convertidas em `BusinessRuleViolation` antes de retornar Ã  Layer 2.

---

### ğŸ”’ **REGRAS ARQUITETURAIS IMUTÃVEIS**

#### **REGRA 1: HIERARQUIA SEM BYPASS**

```yaml
OBRIGATÃ“RIO:
PROIBIDO:
PROIBIDO:
```

#### **REGRA 2:**

```yaml
OBRIGATÃ“RIO: ""
PROIBIDO: ""
OBRIGATÃ“RIO: ""
```

#### **REGRA 3: SINGLE RESPONSIBILITY**

```yaml

```

#### **REGRA 4: DEPENDENCY DIRECTION**

```yaml
PERMITIDO: "Camada superior â†’ Camada inferior"
PROIBIDO: "Camada inferior â†’ Camada superior"
PROIBIDO: "DependÃªncias circulares entre camadas"
```

---

### ğŸ§ª **VALIDAÃ‡ÃƒO ARQUITETURAL OBRIGATÃ“RIA**

#### **TESTES DE COMPLIANCE**

```python

```

---

### ğŸ“Š **MÃ‰TRICAS DE COMPLIANCE OBRIGATÃ“RIAS**

#### **QUALITY GATES ENTERPRISE**

```yaml
Complexity_Cognitive: '< 15 (SonarQube compliant)'
Exception_Handling: 'EspecÃ­fico - sem Exception genÃ©rico'
Code_Duplication: 'Zero duplicaÃ§Ã£o via Constants Factory'
Architecture_Layers: 'MÃ¡ximo 4 camadas na hierarquia'
GraphState_Usage: '100% nas funÃ§Ãµes principais'
Strategy_Pattern: 'ObrigatÃ³rio para algoritmos plugÃ¡veis'
Thread_Safety: 'ObrigatÃ³rio para estado compartilhado'
```

---

## ğŸ–ï¸ COMPLIANCE ENFORCEMENT

```yaml
Rule Compliance:
  - ğŸ”’ revision_mandatory_for_changes: true
  - ğŸ”’ documentation_always_updated: true
  - ğŸ”’ compliance_verified_automatically: true
  - ğŸ”’ apply_manually: >
      this rule needs to be mentioned to be included
```

---

## ğŸ”— CROSS-REFERENCE TABLE

> **Quick Navigation:** Jump between implementations (this doc) and architectural concepts ([project-rules.md](project-rules.md))

| Implementation                    | This Doc (Lines)          | project-rules.md (Lines)   | Files                                                                 |
| --------------------------------- | ------------------------- | -------------------------- | --------------------------------------------------------------------- |
| **Clean Architecture (4 Layers)** | 91-1087                   | 79-95                      | Multiple (see below)                                                  |
| Layer 1: Presentation             | 91-303                    | 79-95                      | `scripts/chat.py`, `src/features/conversation/conversation.py`        |
| Layer 2: Orchestration            | 304-655                   | 79-95                      | `src/features/conversation/graph.py`, `src/features/rag/graph.py`     |
| Layer 3: Business Logic           | 656-887                   | 79-95                      | `src/features/rag/nodes.py`, `src/features/reranking/reranker.py`     |
| Layer 4: Services                 | 888-1087                  | 79-95                      | `src/infrastructure/config/settings.py`, `src/core/services/`         |
| **RAGState (TypedDict)**          | 91-303, 304-655, 656-887  | 124-171 (Abstraction)      | `src/core/domain/state.py`                                            |
| **SessionConfig (Pydantic)**      | 1294-1380 (DI pattern)    | 172-218, 444-594           | `src/core/domain/session.py`                                          |
| **LangGraph Integration**         | 304-655 (Layer 2)         | 79-95, 255-311             | `src/features/conversation/graph.py`, `src/features/rag/graph.py`     |
| **Strategy Pattern**              | 1222-1293                 | 255-311 (Polymorphism)     | `src/features/rag/nodes.py` (retrieve_adaptive, rerank_documents)     |
| **Dependency Injection**          | 1294-1380                 | 444-594 (Composition)      | `src/core/domain/session.py` (SessionConfig composition)              |
| **Exception Hierarchy**           | 1381-1470                 | Implicit in error handling | Custom exceptions, retry logic                                        |
| **Communication Patterns**        | 1124-1219                 | Implicit                   | Thread-safety, validation enterprise                                  |
| **Architectural Rules**           | 1471-1504                 | 595-773 (Compliance)       | Hierarchy enforcement, no bypass, single responsibility               |
| **Validation & Metrics**          | 1505-1530                 | 595-773 (Compliance)       | Compliance tests, import-linter, coverage metrics                     |
| **SOLID Principles**              | Applied throughout        | 96-119                     | All implementation files                                              |
| **Abstraction (TypedDict)**       | 91-303 (RAGState)         | 124-171                    | `src/core/domain/state.py`                                            |
| **Encapsulation (Pydantic)**      | 1294-1380 (SessionConfig) | 172-218                    | `src/core/domain/session.py`, `src/infrastructure/config/settings.py` |
| **Inheritance (BaseSettings)**    | 1294-1380 (DI)            | 219-254                    | `src/core/domain/session.py`, `src/infrastructure/config/settings.py` |
| **Polymorphism (Strategy)**       | 1222-1293                 | 255-311                    | `src/features/rag/nodes.py`                                           |
| **Composition**                   | 1294-1380 (SessionConfig) | 444-594                    | `src/core/domain/session.py`                                          |

## ğŸ“š RELATED DOCUMENTS

| Document                                     | Relevant Sections                                               | Description                                          |
| -------------------------------------------- | --------------------------------------------------------------- | ---------------------------------------------------- |
| [project-rules.md](project-rules.md)         | Lines 79-119 (Architecture+SOLID), Lines 124-594 (OOP Patterns) | Architectural concepts, SOLID principles, OOP theory |
| [behavioral-rules.md](behavioral-rules.md)   | Lines 45-78 (ROI Framework), Lines 135-175 (Token Efficiency)   | Execution protocols, efficiency standards            |
| [methodology-rules.md](methodology-rules.md) | Lines 25-60 (TDD), Lines 85-120 (XP+Kanban+OOP)                 | Development workflow, quality metrics                |
| [tools-rules.md](tools-rules.md)             | Lines 30-80 (CLI tools), Lines 120-180 (Terminal)               | Tool usage, performance optimization                 |
| [mcp-rules.md](mcp-rules.md)                 | Lines 16-34 (Pattern 1), Lines 36-51 (Pattern 2)                | MCP integration patterns, workflow                   |

---

**ğŸ“… Created:** 06/08/2025
**ğŸ”„ Last Update:** 17/10/2025
**ğŸ“‹ Status:** ACTIVE AND MANDATORY
**ğŸ¯ Application:** AWAYS WHEN THE USER MENTIONS OR WHEN THE AGENT NEEDS CONTEXT OR RELEVANT INFORMATION ABOUT THE PROJECT

- **ğŸ” Linked:** [.github\copilot-rules\project-rules.md](project-rules.md)

---

_Este padrÃ£o arquitetural Ã© **IMUTÃVEL** e deve ser seguido em toda expansÃ£o futura do projeto._
